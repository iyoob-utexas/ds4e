{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zjhtaC-TAnqE",
        "60iOOpLQAtZT"
      ],
      "authorship_tag": "ABX9TyMV7NZL2HL2YaVRmNqssYoQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iyoob-utexas/ds4e/blob/main/notebooks/generate_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resident Match - Generate Metrics\n",
        "This code generates the metrics for Resident Matching."
      ],
      "metadata": {
        "id": "-lUKdCsT_KP3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize"
      ],
      "metadata": {
        "id": "d5FoRirZkuy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Install Libraries"
      ],
      "metadata": {
        "id": "zjhtaC-TAnqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF\n",
        "!pip install openai\n",
        "!pip install pandas\n",
        "!pip install colab-env -qU"
      ],
      "metadata": {
        "id": "a-vYbupfkggT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86a7fe0c-a3bf-443f-a0d2-7e5f450db958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.24.12)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for colab-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF for PDF processing\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import openai"
      ],
      "metadata": {
        "id": "K2llsLjo43Uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load Creds"
      ],
      "metadata": {
        "id": "60iOOpLQAtZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "y60lE09wiQZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "119c7384-493d-4a1f-a785-f393a7588d39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "rxl8HBDbt6sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load openai api credentials if stored in json (NON-COLAB)\n",
        "def load_credentials():\n",
        "    with open(\"config/credentials.json\", \"r\") as f:\n",
        "        creds = json.load(f)\n",
        "    return creds\n",
        "\n",
        "credentials = load_credentials()\n",
        "openai.api_type = credentials[\"api_type\"]\n",
        "openai.api_base = credentials[\"api_base\"]\n",
        "openai.api_version = credentials[\"api_version\"]\n",
        "openai.api_key = credentials[\"api_key\"]"
      ],
      "metadata": {
        "id": "jEWkAKpg6zko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to send a prompt to ChatGPT\n",
        "def ChatAPI(prompt):\n",
        "    client = openai.OpenAI()\n",
        "    #load_dotenv()\n",
        "    response = openai.chat.completions.create(\n",
        "      # engine=\"test-poc\",\n",
        "      model = \"gpt-4o\",\n",
        "      messages = [{\"role\":\"system\",\"content\":\"You are an AI assistant that helps people find information.\"},{\"role\":\"user\",\"content\":prompt}],\n",
        "      temperature=0,\n",
        "      max_tokens=1000,\n",
        "      top_p=0.95,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0,\n",
        "      stop=None)\n",
        "    text = response.choices[0].message.content\n",
        "    return text"
      ],
      "metadata": {
        "id": "MSgplMkJ7THJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mCbQFJeKgj3"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78bce3ef-fd90-4a95-a88f-25033da7f6d2"
      },
      "outputs": [],
      "source": [
        "current_year = 2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWY40jnhLp3D"
      },
      "outputs": [],
      "source": [
        "# File paths\n",
        "input_path = '/content/gdrive/MyDrive/Colab Notebooks/dellmc/data/'\n",
        "ref_path = '/content/gdrive/MyDrive/Colab Notebooks/dellmc/ref/'\n",
        "output_path = '/content/gdrive/MyDrive/Colab Notebooks/dellmc/out/'\n",
        "\n",
        "#input_path = 'raw/'\n",
        "#ref_path = 'ref/'\n",
        "#output_path = 'output/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dff0a8b-e1cc-492a-837b-0b1777539e9b"
      },
      "outputs": [],
      "source": [
        "# Load all input pdf files\n",
        "files = [file for file in os.listdir(input_path) if file!='.DS_Store']\n",
        "files_sort = [[i, i[6:10] + '-' + i[0:2] + '-' + i[3:5]] for i in files]\n",
        "files_sort.sort(key = lambda x: x[1])\n",
        "files = [i[0] for i in files_sort]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b904ef30-233f-40ac-b559-c88da9d2c8a4"
      },
      "outputs": [],
      "source": [
        "# Load ref files\n",
        "state_regions = pd.read_csv('' + ref_path + 'States_and_Regions_Categorization.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4aG6WshK6rr"
      },
      "source": [
        "### Extract Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f814ab8-d90c-4310-99cd-2cebaecbecf2"
      },
      "outputs": [],
      "source": [
        "# Extract text from the PDF\n",
        "def extract_text_from_pdf(doc):\n",
        "    text = \"\"\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        text += page.get_text()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38e9b6b6-54fb-4c8d-a87d-56115a92c1b9",
        "outputId": "7db75a0e-d2b8-4c4a-8947-72d01d144166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 968 ms, sys: 67 ms, total: 1.03 s\n",
            "Wall time: 8.47 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "candidates_df = pd.DataFrame(columns=['candidate_id', 'candidate_doc'])\n",
        "pdf_text_dict = {}\n",
        "for file in files:\n",
        "    candidate_id = file.split('_')[-3]\n",
        "    pdf_path = input_path + file\n",
        "    doc = fitz.open(pdf_path)\n",
        "    pdf_text = extract_text_from_pdf(doc)\n",
        "\n",
        "    # Adding candidate PDF text to pdf_text_dict\n",
        "    pdf_text_dict[candidate_id] = pdf_text\n",
        "    candidates_df.loc[len(candidates_df)] = [candidate_id, file]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHhaOAu0K_mz"
      },
      "source": [
        "## Generate Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "296270f6-2815-469f-bb6b-66c5eff5ca88"
      },
      "outputs": [],
      "source": [
        "# Function to extract state from an address\n",
        "def address_state_region(address):\n",
        "    state_matches = []\n",
        "    if address:\n",
        "        # Add District Of Colubmia to region file\n",
        "        if 'district of columbia' in address.lower():\n",
        "            return 'NE'\n",
        "        for state_name in state_regions['State'].unique():\n",
        "            if state_name in address:\n",
        "                state_matches.append(state_name)\n",
        "        if len(state_matches) > 1:\n",
        "            # print('Multiple states identified in this address: ' + address)\n",
        "            # The following line of code finds which matched state occurred last in the address string, this will be the one that is actually the state\n",
        "            state_matches = sorted(state_matches, key=lambda word: address.rfind(word))\n",
        "            return state_regions.loc[state_regions['State']==state_matches[-1]]['Region'].iloc[0]\n",
        "        elif len(state_matches) == 0:\n",
        "            for state in state_regions['State'].unique():\n",
        "                if state in address:\n",
        "                    state_matches.append(state)\n",
        "            if len(state_matches) > 1:\n",
        "                # print('Multiple states identified in this address: ' + address)\n",
        "                state_matches = sorted(state_matches, key=lambda word: address.rfind(word))\n",
        "                return state_regions.loc[state_regions['State']==state_matches[-1]]['Region'].iloc[0]\n",
        "            elif len(state_matches) == 1:\n",
        "                return state_regions.loc[state_regions['State']==state_matches[-1]]['Region'].iloc[0]\n",
        "            else:\n",
        "                return\n",
        "        else:\n",
        "            return state_regions.loc[state_regions['State']==state_matches[-1]]['Region'].iloc[0]\n",
        "    else:\n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c9c1a67-abf7-49ad-800c-067b8476335f"
      },
      "source": [
        "### Candidate Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00382ebb-2359-470b-8b1a-1aec08f95d86"
      },
      "outputs": [],
      "source": [
        "def candidate_metadata(candidate_id):\n",
        "    pdf_text = pdf_text_dict[candidate_id]\n",
        "\n",
        "    # Including text until EXAMINATIONS section for the basic info section in case text is out of place\n",
        "    basic_info_pattern = r'(.*?)\\nEXAMINATIONS'\n",
        "    basic_info_match = re.search(basic_info_pattern, pdf_text, re.DOTALL)\n",
        "    if basic_info_match:\n",
        "        basic_info_text = basic_info_match.group(1)\n",
        "\n",
        "        # Extracting candidate name from basic info section\n",
        "        name_pattern = r'\\n(.*?)\\s*ID:'\n",
        "        name_match = re.findall(name_pattern, basic_info_text)\n",
        "        if len(name_match) > 0:\n",
        "            name = name_match[0]\n",
        "        else:\n",
        "            name = None\n",
        "\n",
        "        # Extracting candidate email from basic info section\n",
        "        email_pattern = r'Email:\\n(.*?)\\s*\\nCell Phone'\n",
        "        email_match = re.findall(email_pattern, basic_info_text)\n",
        "        if len(email_match) > 0:\n",
        "            email = email_match[0]\n",
        "        else:\n",
        "            email = None\n",
        "\n",
        "        # Extracting candidate phone number from basic info section\n",
        "        phone_pattern = r'Cell Phone:\\n(.*?)\\s*\\nPronouns'\n",
        "        phone_match = re.findall(phone_pattern, basic_info_text)\n",
        "        if len(phone_match) > 0:\n",
        "            phone = phone_match[0]\n",
        "        else:\n",
        "            phone = None\n",
        "\n",
        "        # Extracting candidate medical school from basic info section\n",
        "        # med_school_pattern = r'Medical School:\\n(.*?)\\s*\\nMedical School Country'\n",
        "        # med_school_match = re.findall(med_school_pattern, basic_info_text)\n",
        "        # if len(med_school_match) > 0:\n",
        "        #     med_school = med_school_match[0]\n",
        "        # else:\n",
        "        #     med_school = None\n",
        "\n",
        "        # Extracting candidate permanent address and region\n",
        "        candidate_address_pattern = r'Address:\\n(.*?)\\s*\\nPermanent Address'\n",
        "        candidate_address_match = re.findall(candidate_address_pattern, basic_info_text)\n",
        "        if len(candidate_address_match) > 0:\n",
        "            candidate_address = candidate_address_match[0]\n",
        "            candidate_address_region = address_state_region(candidate_address)\n",
        "        else:\n",
        "            candidate_address = None\n",
        "            candidate_address_region = None\n",
        "\n",
        "    else:\n",
        "        name = None\n",
        "        email = None\n",
        "        phone = None\n",
        "        candidate_address = None\n",
        "        candidate_address_region = None\n",
        "        # med_school = None\n",
        "\n",
        "    return pd.Series([name, email, phone, candidate_address, candidate_address_region])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e77ec26-7e90-4487-a620-df09d6b136af"
      },
      "outputs": [],
      "source": [
        "candidates_df[['candidate_name', 'candidate_email', 'candidate_phone', 'candidate_address', 'candidate_address_region']] = candidates_df.apply(lambda x: candidate_metadata(x['candidate_id']), axis=1)\n",
        "candidates_df = candidates_df[['candidate_id', 'candidate_name', 'candidate_email', 'candidate_phone', 'candidate_address', 'candidate_address_region', 'candidate_doc']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86cc6340-5b17-4a90-b160-76c2da6542da"
      },
      "outputs": [],
      "source": [
        "candidates_df.to_csv('' + output_path + 'candidate.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cd907f7-0c6e-40db-a73b-dbeb938700b0"
      },
      "outputs": [],
      "source": [
        "candidates_df = pd.DataFrame()\n",
        "candidates_df['candidate_id'] = pdf_text_dict.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMM2w5G6LEpM"
      },
      "source": [
        "### Education"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63ac3b79-8ab0-4422-9fd5-2c01fc83f485"
      },
      "outputs": [],
      "source": [
        "def education_metrics(candidate_id):\n",
        "    pdf_text = pdf_text_dict[candidate_id]\n",
        "    education_pattern = r'EDUCATION\\n(.*?)\\nEXAMINATIONS'\n",
        "    education_match = re.search(education_pattern, pdf_text, re.DOTALL)\n",
        "\n",
        "    if education_match:\n",
        "        education_text = education_match.group(1)\n",
        "        undergrad_gpa_pattern = r'GPA:\\s*(\\d+\\.\\d+)'\n",
        "        undergrad_gpa_match = re.findall(undergrad_gpa_pattern, education_text)\n",
        "        # Take the last GPA found in the education text, as this will be the undergrad GPA - confirm this logic\n",
        "        undergrad_gpa = float(undergrad_gpa_match[-1]) if undergrad_gpa_match else None\n",
        "\n",
        "        # aoa_pattern = r'AOA:\\s*(Yes|No)'\n",
        "        aoa_result_pattern = r'AOA\\s?:\\s?(.*?)\\n'\n",
        "        aoa_result_match = re.search(aoa_result_pattern, education_text)\n",
        "        if aoa_result_match:\n",
        "            aoa_result_text = aoa_result_match.group(1)\n",
        "            aoa_selected_pattern = r'\\b(I have been selected|AOA)\\b'\n",
        "            aoa_selected_result = re.findall(aoa_selected_pattern, aoa_result_text)\n",
        "            aoa = 1 if len(aoa_selected_result) > 0 else 0\n",
        "        else:\n",
        "            aoa = 0\n",
        "\n",
        "        medical_school_name_pattern = r'Medical School\\n(.*?)\\nAddress'\n",
        "        medical_school_name_match = re.findall(medical_school_name_pattern, education_text, re.DOTALL)\n",
        "        if len(medical_school_name_match) > 0:\n",
        "            medical_school_name = medical_school_name_match[0]\n",
        "        else:\n",
        "            medical_school_name = None\n",
        "\n",
        "        medical_school_address_pattern = r'Medical School.*?Address:\\s?(.*?)\\nAAMC'\n",
        "        medical_school_address_match = re.findall(medical_school_address_pattern, education_text, re.DOTALL)\n",
        "        if len(medical_school_address_match) > 0:\n",
        "            medical_school_address = medical_school_address_match[0]\n",
        "            medical_school_region = address_state_region(medical_school_address)\n",
        "        else:\n",
        "            medical_school_address = None\n",
        "            medical_school_region = None\n",
        "\n",
        "    else:\n",
        "        undergrad_gpa = None\n",
        "        aoa = 0\n",
        "        medical_school_name = None\n",
        "        medical_school_address = None\n",
        "        medical_school_region = None\n",
        "\n",
        "    return pd.Series([undergrad_gpa, aoa, medical_school_name, medical_school_address, medical_school_region])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68cfa87e-2dc7-433d-a775-0046b30b6bef"
      },
      "outputs": [],
      "source": [
        "# Education Output\n",
        "education_df = candidates_df.copy()\n",
        "education_df[['education_undergrad_gpa', 'education_aoa', 'education_medschool', 'education_medical_school_address', 'education_medical_school_region']] = education_df.apply(lambda x: education_metrics(x['candidate_id']), axis=1)\n",
        "education_df.to_csv(output_path + 'education.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdf9964c-570d-4b1c-b0bb-6d05f6647c08"
      },
      "source": [
        "### Examinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95b51d44-f9e4-4b51-b7d5-af06d846644d"
      },
      "outputs": [],
      "source": [
        "# Extracting Examinations Information\n",
        "# Run this block to extract the examination-related information\n",
        "def examinations_metrics(candidate_id):\n",
        "    pdf_text = pdf_text_dict[candidate_id]\n",
        "    # usmle_step2_pattern = r'Step 2 CK\\s+(\\d{3})'\n",
        "    usmle_step2_pattern = r'Step 2 CK\\n.*\\n(\\d{3})'\n",
        "    usmle_step2_match = re.search(usmle_step2_pattern, pdf_text)\n",
        "    usmle_step2_score = int(usmle_step2_match.group(1)) if usmle_step2_match else None\n",
        "\n",
        "    return usmle_step2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc30b455-d061-44df-8035-d74cc3be4691"
      },
      "outputs": [],
      "source": [
        "# Examinations Output\n",
        "examinations_df = candidates_df.copy()\n",
        "examinations_df['examinations_step2_score'] = examinations_df.apply(lambda x: examinations_metrics(x['candidate_id']), axis=1)\n",
        "examinations_df.to_csv(output_path + 'examinations.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47f35b7c-f504-4e98-8767-6de2b811a3a6"
      },
      "source": [
        "### Employment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "396441d4-71bc-4c34-9805-12042bd6667a"
      },
      "outputs": [],
      "source": [
        "# Extracting Employment Information\n",
        "# Run this block to extract the employment-related information\n",
        "def employment_metrics(candidate_id):\n",
        "    pdf_text = pdf_text_dict[candidate_id]\n",
        "    employment_pattern = r'EMPLOYMENT\\n(.*?)\\nPUBLICATIONS'\n",
        "    employment_match = re.search(employment_pattern, pdf_text, re.DOTALL)\n",
        "\n",
        "    if employment_match:\n",
        "        employment_text = employment_match.group(1)\n",
        "        years_experience_pattern = r'(\\d{4}) - .*?(\\d{4})'\n",
        "        years_experience_matches = re.findall(years_experience_pattern, employment_text)\n",
        "        # Check for current jobs (present)\n",
        "        present_jobs_pattern = r'\\d{4} - .*?present'\n",
        "        present_jobs_matches = re.findall(present_jobs_pattern, employment_text)\n",
        "        if len(years_experience_matches) > 0:\n",
        "            first_year_experience = int(min([min(i) for i in years_experience_matches]))\n",
        "            latest_year_experience = int(max([max(i) for i in years_experience_matches]))\n",
        "            # If candidate has a current job, set latest year of experience to current year\n",
        "            if len(present_jobs_matches) > 0:\n",
        "                latest_year_experience = current_year\n",
        "            if latest_year_experience == first_year_experience:\n",
        "                years_experience = 1\n",
        "            else:\n",
        "                years_experience = latest_year_experience - first_year_experience\n",
        "        else:\n",
        "            years_experience = 0\n",
        "\n",
        "        number_of_jobs = len(years_experience_matches) + len(present_jobs_matches)\n",
        "\n",
        "        job_description_pattern = r'\\n(.*?)\\nEmployer name'\n",
        "        job_descriptions = re.findall(job_description_pattern, employment_text)\n",
        "        service_experience_gpt_call = 'From the following list of job descriptions, are any of the jobs service industry jobs, for example server or cashier? Return either 1 for yes or 0 for No.'\n",
        "        service_experience = ChatAPI(service_experience_gpt_call + str(job_descriptions))\n",
        "\n",
        "        try:\n",
        "            service_experience = int(service_experience)\n",
        "        except:\n",
        "            service_experience = 0\n",
        "\n",
        "    else:\n",
        "        years_experience = 0\n",
        "        number_of_jobs = 0\n",
        "        service_experience = 0\n",
        "\n",
        "    return pd.Series([years_experience, number_of_jobs, service_experience])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fee4ddaf-16ae-40bf-b10c-037b9a02d47f"
      },
      "outputs": [],
      "source": [
        "# Employment Output\n",
        "employment_df = candidates_df.copy()\n",
        "employment_df[['employment_years_experience', 'employment_number_of_jobs', 'employment_service_experience']] = employment_df.apply(lambda x: employment_metrics(x['candidate_id']), axis=1)\n",
        "employment_df.to_csv(output_path + 'employment.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f27cec75-09a0-42e0-8a97-3008836929f4"
      },
      "source": [
        "### Publications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "698026a7-9de5-476c-af16-18f8af83d093"
      },
      "outputs": [],
      "source": [
        "# Extracting Publications Information\n",
        "# Run this block to extract the publications information\n",
        "def publications_metrics(candidate_id):\n",
        "    pdf_text = pdf_text_dict[candidate_id]\n",
        "    # Expanding text window to start at education section, because some of the papers appeared before the PUBLICATIONS header in the pdf text\n",
        "    publications_pattern = r'EDUCATION\\n(.*?)\\nHONORS AND INTERESTS'\n",
        "    publications_match = re.search(publications_pattern, pdf_text, re.DOTALL)\n",
        "\n",
        "    if publications_match:\n",
        "        publications_text = publications_match.group(1)\n",
        "        peer_reviewed_publication_pattern = r'Type:\\s?Peer-Reviewed Article \\(Published\\)'\n",
        "        peer_reviewed_publication_matches = re.findall(peer_reviewed_publication_pattern, publications_text)\n",
        "        peer_reviewed_publications = len(peer_reviewed_publication_matches)\n",
        "\n",
        "        # Only finding number of first authors for peer reviewed published articles\n",
        "        first_author_pattern = r'Type:\\s?Peer-Reviewed Article \\(Published\\).*?First/Senior Author:\\s?([a-zA-Z]+)\\n'\n",
        "        first_author_matches = re.findall(first_author_pattern, publications_text, flags=re.DOTALL)\n",
        "        first_author_matches = [i for i in first_author_matches if i.lower()=='yes']\n",
        "        first_authors = len(first_author_matches)\n",
        "\n",
        "        oral_presentation_location_pattern = r'Type:\\s?Oral Presentation.*?Address:\\s?(.*?)\\n'\n",
        "        oral_presentation_locations = re.findall(oral_presentation_location_pattern, publications_text, flags=re.DOTALL)\n",
        "\n",
        "    else:\n",
        "        peer_reviewed_publications = 0\n",
        "        first_authors = 0\n",
        "\n",
        "    return pd.Series([peer_reviewed_publications, first_authors])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8acf6d7d-5b1e-4601-a600-9c4282db72c2"
      },
      "outputs": [],
      "source": [
        "# Publications Output\n",
        "publications_df = candidates_df.copy()\n",
        "publications_df[['publications_peer_reviewed', 'publications_first_authors']] = publications_df.apply(lambda x: publications_metrics(x['candidate_id']), axis=1)\n",
        "publications_df.to_csv(output_path + 'publications.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be6bbff6-e5f9-4d57-8441-9b023387c818"
      },
      "source": [
        "### Honors and Interests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00683c83-482c-4b5d-a4c0-00b81eb6fa4b"
      },
      "outputs": [],
      "source": [
        "# Extracting Honors and Interests Information\n",
        "# Run this block to extract the honors and interests information\n",
        "def honors_interests_metrics(candidate_id):\n",
        "    pdf_text = pdf_text_dict[candidate_id]\n",
        "    honors_interests_pattern = r'HONORS AND INTERESTS\\n(.*?)\\nREQUIRED SUPPLEMENTAL FORM'\n",
        "    honors_interests_match = re.search(honors_interests_pattern, pdf_text, re.DOTALL)\n",
        "\n",
        "    if honors_interests_match:\n",
        "        honors_interests_text = honors_interests_match.group(1)\n",
        "        # Keywords that indicate monetary value\n",
        "        monetary_value_list = ['grant', 'scholarship']\n",
        "        grant_scholarship_pattern = r'\\b(grant|scholarship)\\b'\n",
        "        grant_scholarship_match = re.findall(grant_scholarship_pattern, honors_interests_text, flags = re.IGNORECASE)\n",
        "        # Probably double counting some occurences\n",
        "        # Turning this into a binary output until we fix above bug\n",
        "        grants_scholarships = len(grant_scholarship_match)\n",
        "        if grants_scholarships > 0:\n",
        "            grants_scholarships = 1\n",
        "\n",
        "        # There is a label at the beginning of the Honors and Interests section that includes hobbies, must look for the hobbies header after this\n",
        "        hobbies_pattern = r'hobbies\\n.*?\\s*Hobbies\\s*(.*?)$'\n",
        "        hobbies_match = re.search(hobbies_pattern, honors_interests_text, flags= re.DOTALL | re.IGNORECASE)\n",
        "        if hobbies_match:\n",
        "            hobbies_text = hobbies_match.group(1)\n",
        "            # In hobbies section taking every text snippet after a new line as a hobby, this will lead to some invalid values, but GPT might be able to ignore these\n",
        "            # Formatting of this section is inconsistent between applications\n",
        "            hobbies_list_pattern = r'[^\\n]+'\n",
        "            hobbies_list_match = re.findall(hobbies_list_pattern, hobbies_text)\n",
        "        else:\n",
        "            # print(candidate_id)\n",
        "            distinctive_hobbies = 0\n",
        "\n",
        "    else:\n",
        "        grants_scholarships = 0\n",
        "\n",
        "    return pd.Series([grants_scholarships])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d15c56c3-97d2-4c77-b3a0-37abb6083a4d"
      },
      "outputs": [],
      "source": [
        "# Honors and Interests Output\n",
        "honors_interests_df = candidates_df.copy()\n",
        "honors_interests_df[['honors_interests_grants_scholarships']] = honors_interests_df.apply(lambda x: honors_interests_metrics(x['candidate_id']), axis=1)\n",
        "honors_interests_df.to_csv(output_path + 'honors_interests.csv', index=False)"
      ]
    }
  ]
}